% vim:spell:spelllang=en_gb:

In this chapter we will document our prototype language, Join.  The
language is very similar to the original core join-calculus in many
aspects, but has been extended with various syntactic and semantic
features. In the following sections, we will present each extension
and discuss our motivation for including it, as well as the possible
implications that it may have on the difficulty of implementing the
language for real-world applications.

At last we will document the final syntax and semantics of the Join
language language.

\section{The core calculus}
\fixme{move some of the stuff from the introduction here, since an introduction
should rather introduce the project and more abstract concepts than the
programming language, in my opinion.. RFC..}

\section{Pattern matching}
In the core calculus it is only possible to construct join patterns, that match
atom names, fully disregarding the data contents of the atoms. Thus, if one wishes
to have different reactions to take place for different types of content, one
has to use different atom names to signify this.

Consider for example these two similar implementations of a stack, drawn from \cite{MaMa2008AlgPat} :
\begin{displaymath}
\begin{array}{rcll}
\defJ
\\ & &  \atm some<x> \andJ \atm push<y>&\toJ0 \atm some<y:x>
\\ &\orJ&\atm empty<> \andJ \atm push<y> &\toJ0 \atm some<y>
\\ &\orJ&\atm some<x> \andJ \atm pop<k> &\toJ0  \match x \with
\\ &&& \qquad         x':[] \to \atm k<x> \andJ \atm empty<>
\\ &&& \qquad    | x':xs \to \atm k<x> \andJ \atm some<xs>
\\&\inJ& \atm empty<> \andJ \ldots
\\
\\\defJ &&&
\\ & &   \atm stack<x> \andJ \atm push<y> &\toJ0 \atm stack<y:x>
\\&\orJ&  \atm stack<x:xs> \andJ \atm pop<k>& \toJ0 \atm stack<xs> \andJ \atm k<x>
\\&\inJ& \atm stack<[]> \andJ \ldots
\end{array}
\end{displaymath}

Even superficial inspection reveals the latter to be preferable, as it is both
more compact, more readable and more intuitive to someone who has tried
programming with pattern matching like that of ML or Haskell.

Also, it simply seems as a natural extension of the core join calculus.

Because of this we have decided to include pattern matching on join patterns in our system.
The precise semantics of pattern matching can be found in Figure \ref{fig:rule:pat}.

\section{Distribution and mobility}
The model of distribution is based on the concept of \emph{locations}, which
are named collections of definitions and atoms, thus comprising separate
join-calculus machines. Besides this, locations are characterised by being able
to migrate from site to site by producing a special atom, $\Go<a,k>$, where $a$
is the name of the destination location and $\atm k <>$ is a continuation to be
triggered upon successful migration. Furthermore they are able to become inert
by producing the special atom, $\Halt<>$, in their context.

As a consequence, locations form a hierarchy or tree, that changes throughout
the execution of the join program as locations migrate and halt.
When a location decides to migrate or halt, the decision has consequences for
the entire branch of the location tree, of which the migrating or halting
location is the root. Therefore, when a location migrates, the entire set of
sublocations also migrates, and halting similarly halts every sublocation.

\section{Timing}

The core join-calculus has no notion of time, which makes it
impossible to reason about the behaviour of programs with real-time
constraints.  For instance, in distributed systems, it is common to
place a time constraint on external requests, to make sure that a
program don't wait for a response forever if a message should get
lost, or if the program in the other end crashes. To express a
constraint like that in the core join calculus would require that we
rely on a specific implementation being able to generate a message on
a given time interval:
\begin{align*}
  \textbf{def}\quad & \S k<x> ~|~ \S incall<> \triangleright P_{ok} \\
  \land\quad & \S timeout<> ~|~ \S incall<> \triangleright P_{error} \\
  \textbf{in}\quad & \S remotecall<k> ~|~ \S starttimer<timeout, 10>
                                      ~|~ \S incall<>
\end{align*}
In the example above, \emph{remotecall} is given $10$ time units to
return a result on the name \emph{k}. If \emph{k} makes it before the
time limit, the process $P_{ok}$ is started, otherwise the process
$P_{error}$ starts.  There is a problem with this approach though:
Even though we can provide a Join-implementation that does exactly as
described, there is no guarantee that the program will behave in a
similar way on different implementations.

The problem lies both in the non-deterministic choice between the two
reaction rules, and in the fact that messages are not required to be
processed in the same order as they arrive. Even if a result arrives
before the timeout fires, a valid implementation can choose to wait
for the \emph{timeout} message to appear, and consume that instead of
the \emph{k} message.

A possible solution to this problem is to extend the join-calculus
with a notion of time. Many other non-timed process calculi, including
CSP and CCS, has already been extended for this purpose. An overview
of some of the work that has been done in this area along with an
attempt to generalize some of the concepts of timed process calculi
has been presented in \cite{nicollin-overview}.

A timed extension also exists for join-calculus, called Timed Join
Calculus \cite{timed-join}. The calculus is extended with a model of
time using a \emph{discrete time domain}, where every process bears a
time tag denoting when it will be able to participate in a reaction.
The syntax is extended with a new tagging construction for processes,
and all reactions are tagged with a
\emph{delay} tag:
\begin{align*}
  P ::={} & ...    & D ::={}& J \stackrel{d}{\triangleright} P \\
          & t : P  &        & D \land D
\end{align*}
We can now model the example above without depending on special
messages that get captured by the environment:
\begin{align*}
  \textbf{def}\quad & \S k<x> ~|~ \S incall<> \triangleright P_{ok} \\
  \land\quad & \S incall<> \stackrel{16}{\triangleright} P_{error} \\
  \textbf{in}\quad & \S 0:remotecall<k> ~|~ \S 0:incall<>
\end{align*}
Here, we assume that the response message \emph{k} gets transferred
from an external location and gets time tagged as soon as it enters
the local solution.  The second reaction rule is tagged with a delay
of $16$ time units.  This means that every message on the left of
``$\triangleright$'' needs to be available for $16$ time units before
the reaction can happen, effectively allowing another reaction to
``steal'' messages in that time window. Rules with no tags implicitly
gets tagged with a delay of $0$. If the \emph{k} message therefore
arrives before the $16$ time units has passed, the first reaction can
take place immediately.


\subsection{Operational semantics}

\fixme{Is it necessary to repeat the operational semantics of the
article, or can we just refer to them?}


\subsection{Infinite instants}

The time domain in Timed Join Calculus is \emph{abstract}, where time
tags doesn't have any quantifiable correspondence with \emph{physical}
time. It is assumed that any computation takes zero time unless
delayed with a non-zero time tag, which is of course not a realistic
assumption, but as assumption that simplifies the model.
Alternatively, one could assume that any atomic computation took some
minimum amount of time, yielding a model that is closer to reality.
However, as argued in \cite{nicollin-overview}, this destroys the
generality of the model, as we will then tie the behaviour of programs
to an arbitrary assumption about execution speed.

Even if we did make very conservative choices for the minimum duration
of a single computation, this wouldn't make it possible to guarantee
that a given computation finishes in a well-defined time window: Since
a computer has finite computational resources, but can (in theory)
execute an arbitrary number of threads concurrently, the time a
computation takes isn't fixed. As an example, say that we choose that
the duration $\delta$ of a reaction in the CHAM is $1 ms$. For a
single process, this will enable us to guarantee that a computation
involving 20 reactions will finish in $20 ms$. But if we execute an
arbitrary number of instances of this process concurrently on the same
hardware, we can only expect that the time it takes for all the
processes to finish will be proportional to the number of processes.
The actual wall-clock time for a single time step therefore increases,
meaning our hypothetical (though conservative) choice is still too
low. If we increase the number of concurrent processes towards
infinity, even the most conservative choice for $\delta$ will result
in an assumption that we can execute an arbitrary number of reactions
in an instant. The result is a more complicated model with exactly the
same problems as the simpler model, where every computation is assumed
to be instantaneous.

Assuming that every atomic computation takes zero time can pose some
problems in the form of \emph{timelocks} (also called
\emph{Zeno-behaviour}). Since time can only progress when a
computation in an instant is done, a diverging computation can prevent
time from ever progressing, causing a global timelock.  In
\cite{timed-join} this is solved by adding a very restrictive type
system to the join calculus, which rejects all programs that aren't
guaranteed to let time progress. We have chosen not to study this type
system in detail, for several reasons: (1) Identifying all
non-timelocking programs is equivalent to solving the halting problem,
meaning that the set of accepted programs in the proposed type system
is a lot smaller than the actual set of valid programs, making it very
difficult to express useful behaviour. (2) The authors describe the
type system as a ``first attempt'' at solving the problem, and are yet
to prove the soundness of it.


\section{Language definition}

\subsection{Syntax}

The syntax of our prototype language is defined in Figure \ref{fig:syntax}. In
this definition, $x,a$ ranges over names, $s$ range over strings of characters,
and $i,d,t \in \mathbb{N}_0$. All constructions marked with ``*'' are syntactic
sugar, and have equivalent encodings in the core Join language.

\begin{figure}
\begin{align*}
P,Q\quad::={}&             && \textbf{processes} \\
          & 0              && \quad\textrm{inert process} \\
 \alt\quad& x\langle e_1, e_2, ..., e_n \rangle
                           && \quad\textrm{asynchronous message} \\
 \alt\quad& P~\&~Q         && \quad\textrm{parallel composition} \\
 \alt\quad& \textbf{def}~D~\textbf{in}~P
                           && \quad\textrm{local definition} \\
 \alt\quad& t : P          && \quad\textrm{timed process} \\
 \alt\quad& \textbf{match}~e~\textbf{with}~\pi_1
               \rightarrow P_1 ~|~ ... ~|~ \pi_n \rightarrow P_n
                           && \quad\textrm{pattern matching} \\
 \alt\quad& \{ I_1; I_2; ...; I_n \}
                           && \quad\textrm{*instruction sequence} \\
D\quad ::={}&              && \textbf{join definitions} \\
         & J \stackrel{d}{\triangleright} P
                           && \quad\textrm{delayed reaction} \\
\alt\quad& D~\textbf{or}~D && \quad\textrm{disjunction} \\
\alt\quad& a[D~\textbf{in}~P] && \quad\textrm{sublocation} \\
J\quad ::={}&              && \textbf{join patterns}\\
         & x\langle \pi_1, \pi_2, ..., \pi_n \rangle
                           && \quad\textrm{message} \\
\alt\quad& x(\pi_1, \pi_2, ..., \pi_n)
                           && \quad\textrm{*synchronous message} \\
\alt\quad& J~\&~J          && \quad\textrm{synchronization} \\
\pi\quad ::={}&            && \textbf{algebraic patterns} \\
         & x               && \quad\textrm{variable} \\
\alt\quad& \kappa(\pi_1, \pi_2, ..., \pi_n)
                           && \quad\textrm{constructor pattern} \\
e\quad ::={}&              && \textbf{expressions} \\
         & i               && \quad\textrm{*integer} \\
\alt\quad& " s "         && \quad\textrm{*string} \\
\alt\quad& x               && \quad\textrm{variable} \\
\alt\quad& \kappa(e_1, e_2, ..., e_n)
                           && \quad\textrm{constructor expression} \\
e^\star\quad ::={}&         && \textbf{*sugared expressions} \\
         & i               && \quad\textrm{*integer} \\
\alt\quad& " s "         && \quad\textrm{*string} \\
\alt\quad& x               && \quad\textrm{*variable} \\
\alt\quad& \kappa(e^\star_1, e^\star_2, ..., e^\star_n)
                           && \quad\textrm{*constructor expression} \\
\alt\quad& x(e^\star_1, e^\star_2, ..., e^\star_ n)
                           && \quad\textrm{*synchronous call} \\
I\quad ::={}&              && \textbf{*instructions} \\
         & \mathbf{let}~\pi~=~e^\star
                           && \quad\textrm{*named values} \\
\alt\quad& \mathbf{run}~P  && \quad\textrm{*asynchronous process} \\
\alt\quad& \mathbf{do}~e^\star && \quad\textrm{*synchronous call} \\
\alt\quad& \textbf{match}~e^\star~\textbf{with}~\pi_1
               \rightarrow \{ I* \} ~|~ ... ~|~ \pi_n \rightarrow \{ I* \}
                           && \quad\textrm{*pattern match} \\
\alt\quad& \textbf{return}~e^\star~\textbf{to}~x
                           && \quad\textrm{*implicit continuation}
\end{align*}
\caption{Syntax of the Join language.\label{fig:syntax}}
\end{figure}


\subsection{Semantics}

We model the state of our system as a series of CHAMs composed in parallel. A
single CHAM is a four tuple $\M = (\D, \A, \phi, t)$ denoted by
\begin{equation*}
 \boxed{\M = \D \mscJ \A}
\end{equation*}
where $\D$ is a set of active definitions, $\A$ is a multiset
of present atoms, $\phi$ is an ordered sequence of location names, and $t$ is
a natural number denoting the current time. Multiple CHAMs are composed in
parallel using the operator $\parallel$. We denote one or more CHAMs composed
in parallel by
\begin{equation*}
 \boxed{\C = \M \Big\slash \C'\parallel\C''}
\end{equation*}

Communication and computation can occur in subsets of the system, without
affecting or knowing the state of the rest of it, which is stated explicitly in
figure \ref{fig:rule:aux}. Some steps, specifically the advancement of time and
process migration, can only occur in a global context where the state of every
machine can be inspected. We denote such a system with $\S_\C$, which means
that the parallel system $\C$ is synchronised, and that process migration and
advancement of time can only happen if every machine in $\C$ is involved. We
denote synchronised and unsynchronised systems with
\begin{equation*}
 \boxed{\mathcal{X} = \S_\C \Big\slash \C}
\end{equation*}

Every semantic rule that requires the presence of an $\S_\C$ construct will be
problematic to implement in a real-world distributed setting, since it is never
possible to know the exact state of every machine in an instant.
\fixme{Discuss why it is ok to implement an obviously unrealistic system, and
how global rules can be removed by throwing away global time synchronisation
and having a better model of process migration.}

A process with its time tags removed is denoted by $P_{\star}$, defined by
\begin{align*}
  (t : x\langle \tilde u \rangle)_\star ={}& x\langle \tilde u \rangle \\
  (t : P)_\star ={}& P_\star \\
  (t : P_1~\&~P_2)_\star ={}& P_{1\star} ~\&~ P_{2\star}
\end{align*}

We say that a join pattern $J$ \emph{matches} a process $P$ when there exists a
$\sigma$ such that $\sigma J = P_\star$, where $\sigma$ is a function that
replaces variable names with closed expressions. Determining whether such a
$\sigma$ exists is stated using the following judgement form:
\begin{equation*}
  \boxed{\P_\mathcal{J}(J,Q) \leadsto \hat\sigma}\footnote{Where $Q$ is a process with no
  time tags. If we need to determine whether $J$ matches a process $P$, then $Q
  = P_\star$.}
\end{equation*}
Where $\hat\sigma$ can denote that a pattern either matches or \emph{fails} to
match a process:
\begin{align*}
 \hat\sigma ::={}& \sigma \\
         |\quad{}& fail
\end{align*}
We use a similar judgement form for expressions: When checking whether a
pattern $\pi$ matches an expression $v$, we denote it with
\begin{equation*}
  \boxed{\P_\Pi(\pi,v) \leadsto \hat\sigma}
\end{equation*}
The rules for these two judgement forms are given in Figure \ref{fig:rule:pat}.

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\P_\J(J,P) \leadsto \hat\sigma$}
\doms{$\P_\Pi(\pi, v) \leadsto \hat\sigma$}
\begin{equation*}
\inferrule[Pat-Var]
{~}
{\P_\Pi(x,v) \leadsto (x \mapsto v)}
\end{equation*}
\begin{equation*}
\inferrule[Pat-Cons]
{\pi = \kappa(\pi_1, \pi_2, ..., \pi_n)
\\ v = \kappa(v_1, v_2, ..., v_n)
\\ \P_\Pi(\pi_1,v_1) \leadsto \sigma_1
\\ \P_\Pi(\pi_2,v_2) \leadsto \sigma_2
\\ ...
\\ \P_\Pi(\pi_n,v_n) \leadsto \sigma_n}
{
 \P_\Pi(\pi,v) \leadsto \sigma_1 \cup \sigma_2 \cup ... \cup \sigma_n
}
\end{equation*}
\begin{equation*}
\inferrule[Pat-Cons-Fail]
{\pi = \kappa(\tilde\pi)
\\ v = \kappa'(\tilde v)
\\ \kappa \not= \kappa'
}
{
 \P_\Pi(\pi, v) \leadsto fail
}
\end{equation*}
\begin{equation*}
\inferrule[Pat-Cons-SubFail]
{\pi = \kappa(\pi_1, \pi_2, ..., \pi_n)
\\ v = \kappa(v_1, v_2, ..., v_m)
\\ \P_\Pi(\pi_i, v_i) \leadsto fail
}
{
 \P_\Pi(\pi, v) \leadsto fail
}
\end{equation*}
\begin{equation*}
\inferrule[Pat-Msg]
{J = x\langle \pi_1, \pi_2, ..., \pi_n \rangle
 \\ P = x\langle v_1, v_2, ..., v_n \rangle
 \\ \P_\Pi(\pi_1,v_1) \leadsto \sigma_1
 \\ \P_\Pi(\pi_2,v_2) \leadsto \sigma_2
 \\ ...
 \\ \P_\Pi(\pi_n,v_n) \leadsto \sigma_n}
{
 \P_\J(J,P) \leadsto \sigma_1 \cup \sigma_2 \cup ... \cup \sigma_n
}
\end{equation*}
\begin{equation*}
\inferrule[Pat-Msg-Fail]
{J = x(\tilde \pi)
\\ P = y(\tilde v)
\\ x \not= y
}
{
 \P_\J(J, P) \leadsto fail
}
\end{equation*}
\begin{equation*}
\inferrule[Pat-Msg-SubFail]
{J = x(\pi_1, \pi_2, ..., \pi_n)
\\ P = x(v_1, v_2, ..., v_m)
\\ \P_\Pi(\pi_i, v_i) \leadsto fail
}
{
 \P_\J(J, P) \leadsto fail
}
\end{equation*}
\end{minipage}}
\caption{Inference rules for pattern matching.} \label{fig:rule:pat}
\end{figure}

When a machine, a parallel composition of machines, or a synchronised system of
machines can make an evaluation step, we denote it with
\begin{equation*}
 \boxed{\mathcal{X} \longrightarrow \mathcal{X}'}
\end{equation*}

We include a relaxed version of the time semantics from \cite{timed-join}. Our
version provides less guarantees about the order in which messages with the
same name is processed, and each CHAM is explicitly tagged with a natural
number that denotes the current time. \fixme{More details about relaxations.}

In the original join-calculus semantics, a two-way reduction relation called a
``heating/cooling relation'' is defined for doing scope extrusion and new
independent locations. We only provide one-way reduction rules for this, namely
\textsc{Red-Def} and \textsc{Red-Loc}, defined in Figure \ref{fig:rule:red}.

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\mathcal{H}(P) \leadsto (\D', \A')$}
\doms{$\widehat\H(D) \leadsto \D$}
\begin{equation*}
\inferrule[Heat-Or]
{D = D_1~\mathbf{or}~D_2
\\ \widehat\H(D_1) \leadsto (\D_1,\A_1)
\\ \widehat\H(D_2) \leadsto (\D_2,\A_2)}
{\widehat\H(D) \leadsto (\D_1 \cup \D_2, \A_1 \uplus \A_2)}
\end{equation*}
\begin{equation*}
\inferrule[Heat-Reaction]
{D = J \stackrel{d}{\triangleright} Q}
{\widehat\H(D) \leadsto \{ D \}}
\qquad
\inferrule[Heat-Location]
{D = a[D~\mathbf{in}~P]}
{\widehat\H(D) \leadsto \{ D \}}
\end{equation*}
\begin{equation*}
\inferrule[Heat-Msg]
{P = \atm t:x<v>}
{\H(P) \leadsto (\emptyset, \{P\})}
\end{equation*}
\begin{equation*}
\inferrule[Heat-Par]
{P = t : (P_1~\&~P_2)
\\ \H(t:P_1) \leadsto (\D_1, \A_1)
\\ \H(t:P_2) \leadsto (\D_2, \A_2)
}
{\H(P) \leadsto (\D_1 \cup \D_2, \A_1 \uplus \A_2)}
\end{equation*}
\begin{equation*}
\inferrule[Heat-Time]
{P = t:(t':P)
\\ \H((t+t'):P) \leadsto (\D, \A)
}
{\H(P) \leadsto (\D,\A)}
\end{equation*}
\begin{equation*}
\inferrule[Heat-Def\footnote{Where $\sigma_{dv}$ replaces fresh names for defined variables.}]
{P = t:\mathbf{def}~D~\mathbf{in}~P
\\ \widehat\H(\sigma_{dv} D) \leadsto \D_1
\\ \H(t: \sigma_{dv} P) \leadsto (\D_2, \A)
}
{\H(P) \leadsto (\D_1 \cup \D_2, \A)}
\end{equation*}
\begin{equation*}
\inferrule[Heat-Match]
{P = t:\mathbf{match}~e~\mathbf{with}~\pi \rightarrow Q~|~\Pi
\\ \P_\Pi(\pi,e) \leadsto \sigma
}
{\H(P) \leadsto (\emptyset, \{ t : \sigma Q \})}
\end{equation*}
\begin{equation*}
\inferrule[Heat-Match-Next]
{~}
{~}
\end{equation*}
\begin{equation*}
\inferrule[Heat-NoMatch]
{~}
{~}
\end{equation*}
\end{minipage}}
\caption{Heating rules}\label{fig:rule:heat}
\end{figure}

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\C\longrightarrow\C'$}
\begin{equation*}
\inferrule[Red-Loc]
{~}
{
\D' \uplus \{ a[D~\mathbf{in}~P] \} \vdash_t^\phi \A
\longrightarrow (D \vdash_t^{\phi a} P) \parallel (\D' \vdash_t^\phi \A)
}
\end{equation*}
\end{minipage}}
\caption{Reduction rules}\label{fig:rule:red}
\end{figure}

To model unreliable communication between locations, we introduce the
$\diamond$ relation, which relates pairs of location names at specific times.
For example, when locations $a$ and $b$ can
communicate at time $t$, we denote it by
\begin{equation*}
 \boxed{a \linkUp{t} b}
\end{equation*}
The relation is reflexive, because internal communication of a machine is
assumed to be reliable. Using this, we can specify how the system behaves when
the connection between two units disappear, as declared by the rules in Figure
\ref{fig:rule:coms}. Note that the rules also state that communication can only
take place when the time of the two communicating machines are synchronised. In
a real world implementation, we would have to drop this requirement.
\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\C \longrightarrow \C'$}
\begin{equation*}
\inferrule[Comm-Link]
{
   \C \equiv \D_1 \mscG{t}{a\phi} \A_1, \atm t:x<\tilde e > \parallel \D_2 \mscG{t}{b\psi} \A_2
\\ a \neq \Omega
\\ b \neq \Omega
\\ \C' \equiv \D_1 \mscG{t}{a\phi} \A_1 \parallel \D_2 \mscG{t}{b\psi} \A_2, \atm (t+1) : x <\tilde e>
\\ x \in dv(\D_2)
\\ a\linkUp{t} b
}
{ \C \longrightarrow \C' }
\end{equation*}
\begin{equation*}
\inferrule[Comm-Lost]
{
   \C \equiv \D_1 \mscG{t}{a\phi} \A_1, \atm t:x< \tilde e >\parallel \D_2 \mscG{t}{b\psi} \A_2
\\ \C' \equiv \D_1 \mscG{t}{a\phi} \A_1 \parallel \D_2 \mscG{t}{b\psi} \A_2
\\ x \in dv(\D_2)
\\ \neg(a \linkUp{t} b)}
{ \C ~\longrightarrow~ \C'}
\end{equation*}
\end{minipage}}
\caption{Inference rules for communication between machines.}\label{fig:rule:coms}
\end{figure}

In our system, time can only progress when no CHAM can take another step,
effectively synchronising all machines on a global clock. In a real setting,
this is of course not feasible, but it makes it easier to reason about
communicating devices in a simulated setting.

When a group of machines $\C$ can no longer make any further computations, they
will be ready to increment their time synchronously, and become the group
$\C'$. We denote this by

\[\boxed{\C \Rightarrow \C'}\]

To be able to detect when a machine can't do any computations, we need to
ensure that no reductions can be applied to the machine, and that all external
communication has been carried out. This is ensured by the
\textsc{Step-Machine} rule in Figure \ref{fig:rule:time-step}.

When all machines have fulfilled the $\Rightarrow$ relation, the time of each machine is
incremented in one global step, as $\S_\C$ is reduced to $\S_{\C'}$, with $\S$ representing
the entire state of the interpreter.

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\C\Rightarrow\C'$} \doms{$\mathcal{X} \longrightarrow \mathcal{X}'$} \doms{$\quiet(\M)$}
\begin{equation*}
\inferrule[Quiet-Machine]
{
\M \equiv \D \mscJ \A \\
\forall P \in \A~.~ \Big( P\equiv t' : a\langle \tilde u  \rangle \land
                    a\in dv[\D]\Big)
\\ \forall D \in \D ~.~ \Big( D \equiv J\toJ{d}Q
                         \land \lnot\exists P' \subseteq\A~.~( \M \timeJ{t'} P'
                         \land t'+d\leq t
                         \land \P (P') \equiv \sigma_{dv}J)\Big)
}
{
  \quiet(\M)
}
\end{equation*}\\
\begin{equation*}
\inferrule[Step-Machine]
{
\M \equiv \D \mscJ \A \\
\quiet(\M) \\
\lnot\exists (t:\Go<a,k>) \in \A \\
}
{
  \M \Rightarrow \D \mscG{t+1}{\phi} \A
}
\end{equation*}\\
\begin{equation*}
\inferrule[Step-Par]
{
  \C \equiv \M \parallel \C' \qquad \C' \Rightarrow \C'' \qquad \M \Rightarrow \M'
}
{
  \C \Rightarrow \M'
}
\qquad
\inferrule[Step-Time]
{
  \C \Rightarrow \C'
}
{
  \S_\C \longrightarrow \S_{\C'}
}
\qquad
\inferrule[Step-System]
{
  \C \longrightarrow \C'
}
{
  \S_\C \longrightarrow \S_{\C'}
}
\end{equation*}
\end{minipage}}
\caption{Inference rules for the progression of time}\label{fig:rule:time-step}
\end{figure}

\subsubsection*{Mobility}
Special meaning is attributed to the messages $\Halt<>$ and
$\Go<a, k>$, and they are regarded as primitives of the
language, separate from normal atoms, though similar in syntax.
\fixme{We need to explain all the rules and judgement forms in Figure
\ref{fig:rule:mig}. Here \emph{may} be dragons.}

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\C\migrates(\phi,\psi)\C$}
\doms{$S_{c} \longrightarrow S_{c'}$}
\doms{$\halted(\M)$}
\begin{equation*}
\inferrule[Mig-Go]
{
  \C\equiv\M\parallel\M_{dest} \\
  \M\equiv\D\mscG{t}{\phi a}\A,t:\Go<b,k> \\
  \M_{dest}\equiv\D'\mscG{t}{\psi b}\A' \\
  \quiet(\M) \\
  \psi \neq \phi a \beta \\
  \lnot \halted(\M_{dest})
}
{
  \C\migrates(\phi a, \psi b a)\D\mscG{t}{\psi b a} \A, \atm k<> \parallel \M_{dest}
}
\end{equation*}

\begin{equation*}
\inferrule[Mig-Recurse]
{
  \C \equiv \M\parallel\C_1 \\
  \M \equiv \D\mscG{t}{\phi a} \A \\
  \C_1\migrates(\phi, \psi)\C_1'
}
{
  \C \migrates(\phi,\psi) \D\mscG{t}{\psi a}\A\parallel\C_1'
}
\end{equation*}

\begin{equation*}
\inferrule[Mig-DontCare]
{
  \C \equiv \M\parallel\C_1 \\
  \M \equiv \D\mscG{t}{\phi} \A \\
  \C_1\migrates(\theta, \psi)\C_1'
}
{
  \C \migrates(\theta,\psi) \M\parallel\C_1'
}
\qquad
\inferrule[Mig-Sys]
{
  \C\migrates(a,b)\C'
}
{
  \S_{\C}\longrightarrow \S_{\C'}
}
\end{equation*}

\begin{equation*}
\inferrule[Mig-Halt]
{
  \M\equiv\D\mscG{t}{\phi a}\A,t:\Halt<> \\
  \quiet(\M)
}
{
  \M\migrates(\phi a, \Omega a)\D\mscG{t}{\Omega a} \A
}\qquad
\inferrule[Halted-Msc]
{
  \C\equiv \D\mscG{t}{\phi}\A\parallel\C' \\
  \phi=\Omega\alpha
}
{
  \halted(\D\mscG{t}{\phi}\A)
}
\end{equation*}
\end{minipage}}
\caption{Inference rules for migration and failure.\label{fig:rule:mig}}
\end{figure}

\newpage
\newpage

\subsection*{Work in progress}

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\widehat\P_\J(J,\A) \leadsto \T_\J$}
\doms{$\T_\J ::= (t,\sigma,\A') ~\big|~ fail$}
\begin{equation*}
\inferrule[Join-FailEmpty]
{~}
{\widehat\P_\J (J, \emptyset) \leadsto fail}
\end{equation*}
\begin{equation*}
 \inferrule[Join-Match]
{
   \A = \{ \atm t:y<\tilde v> \} \uplus \A'
\\ \P_\J(\atm x<\tilde\pi>, \atm y<\tilde v>) \leadsto \sigma
}
{
  \widehat\P_\J(\atm x<\tilde \pi>, \A) \leadsto (t, \sigma, \A')
}
\end{equation*}
\begin{equation*}
\inferrule[Join-SubMatch]
{ \A = \{t : \atm y<\tilde v> \} \uplus \A'
\\ \P_\J(\atm x<\tilde\pi>, \atm y<\tilde v>) \leadsto fail
\\ \widehat\P_\J(\atm x<\tilde\pi>, \A') \leadsto (t',\sigma,\A'')
}
{ \widehat\P_\J(\atm x<\tilde\pi>, \A) \leadsto (t', \sigma, \{ \atm t:y<\tilde v> \} \uplus \A'' ) }
\end{equation*}
\begin{equation*}
\inferrule[Join-FailMatch]
{ \A = \{\atm t:y<\tilde v> \} \uplus \A'
\\ \widehat\P_\J(\atm x<\tilde\pi>, \A') \leadsto fail
\\ \P_\J(\atm x<\tilde\pi>, \atm y<\tilde v>) \leadsto fail }
{\widehat\P_\J(\atm x<\tilde\pi>, \A) \leadsto fail }
\end{equation*}
\end{minipage}}
\caption{Rules for matching single join patterns with failure detection.}
\end{figure}

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\R_r(D,\A,t) \leadsto \T_r$}
\doms{$\T_r ::= (P,\A') ~\big|~ fail$}
\begin{equation*}
\inferrule[Def-Match-Bottom]
{
   D = \atm x<\tilde\pi> \stackrel{d}{\triangleright} Q
\\ \widehat\P_\J(\atm x<\tilde\pi>, \A) \leadsto (t', \sigma, \A')
\\ t'+d \leq t }
{ \R_r(D,~\A,~t) \leadsto (\sigma Q, \A') }
\end{equation*}
\begin{equation*}
\inferrule[Def-Match]
{ D = (\atm x<\tilde\pi> ~\&~ J') \stackrel{d}{\triangleright} Q
\\ \widehat\P_\J(\atm x<\tilde\pi>, \A) \leadsto(t', \sigma, \A')
\\ t' + d \leq t
\\ \R_r(J' \stackrel{d}{\triangleright} Q, ~\A', ~t) \leadsto (Q', \A'') }
{ \R_r(D,A,t) \leadsto (\sigma Q', \A'') }
\end{equation*}
\begin{equation*}
\inferrule[Def-Fail-Late-Bottom]
{ D = \atm x<\tilde\pi> \stackrel{d}{\triangleright} Q
\\ \widehat\P_\J(\atm x<\tilde\pi>, \A) \leadsto (t',\sigma,\A')
\\ t'+d>t
}
{\R_r(D,~\A,~t) \leadsto fail}
\end{equation*}
\begin{equation*}
\inferrule[Def-Fail-Late]
{D = (\atm x<\tilde\pi> ~\&~ J') \stackrel{d}{\triangleright} Q
\\ D' = J \stackrel{d}{\triangleright} Q
\\ \widehat\P_\J(\atm x<\tilde\pi>,\A) \leadsto (t', \sigma, \A')
\\ t'+d>t
}
{
  \R_r(D,\A,t) \leadsto fail
}
\end{equation*}
\begin{equation*}
\inferrule[Def-Fail-Sub]
{D = (\atm x<\tilde\pi> ~\&~ J') \stackrel{d}{\triangleright} Q
\\ D' = J \stackrel{d}{\triangleright} Q
\\ \widehat\P_\J(\atm x<\tilde\pi>,\A) \leadsto (t', \sigma, \A')
\\ \R_r(D',\A',t) \leadsto fail
}
{
  \R_r(D,\A,t) \leadsto fail
}
\end{equation*}
\begin{equation*}
\inferrule[Def-Fail-NoMatch-Bottom]
{ D = \atm x<\tilde\pi> \stackrel{d}{\triangleright} Q
\\ \widehat\P_\J(\atm x<\tilde\pi>, \A) \leadsto fail
}
{\R_r(D,~\A,~t) \leadsto fail}
\end{equation*}
\begin{equation*}
\inferrule[Def-Fail-NoMatch]
{D = (\atm x<\tilde\pi> ~\&~ J') \stackrel{d}{\triangleright} Q
\\ \widehat\P_\J(\atm x<\tilde\pi>, \A) \leadsto fail
}
{
  \R_r(D,\A,t) \leadsto fail
}
\end{equation*}
\end{minipage}}
\caption{Rules for triggering reactions in a solution of messages, and at the same time detecting whether a reaction is able to trigger or not.}
\end{figure}

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\R_m(\M) \leadsto \T_m$}
\doms{$\T_m ::= \M' ~\big|~ quiescent$}

\begin{equation*}
\inferrule[Machine-Step]
{\R_m(\M) \leadsto \M' }
{ \M \longrightarrow \M' }
\end{equation*}

\begin{equation*}
\inferrule[Machine-React]
{\M = \D \vdash_t^\phi \A
 \\ \D = \D' \cup \{ J \stackrel{d}{\triangleright} Q \}
 \\ \R_r(J \stackrel{d}{\triangleright} Q, \A, t) \leadsto (\Q', \A')
}
{
 \R_m(\M) \leadsto \D \vdash_t^\phi \A' \uplus {Q'}
}
\end{equation*}

\begin{equation*}
\inferrule[Machine-React-Next]
{\M = \D \vdash_t^\phi \A
 \\ \D = \D' \cup \{ J \stackrel{d}{\triangleright} Q \}
 \\ \R_r(J \stackrel{d}{\triangleright} Q, \A, t) \leadsto fail
 \\ \R_m(\D' \vdash_t^\phi \A) \leadsto \D' \vdash_t^\phi \A'}
{ \R_m(\M) \leadsto \D \vdash_t^\phi \A' }
\end{equation*}

\begin{equation*}
\inferrule[Machine-Quiescent]
{\M = \D \vdash_t^\phi \A
 \\ \D = \D' \cup \{ J \stackrel{d}{\triangleright} Q \}
 \\ \R_r(J \stackrel{d}{\triangleright} Q, \A, t) \leadsto fail
 \\ \R_m(\D' \vdash_t^\phi \A) \leadsto quiescent
}
{ \R_m(\M) \leadsto quiescent }
\end{equation*}
\begin{equation*}
\inferrule[Machine-Quiescent-Bottom]
{~}
{\emptyset \vdash_t^\phi \A \leadsto quiescent}
\end{equation*}
\end{minipage}}
\caption{Rules for doing reactions in a single machine, and at the same time detecting whether it is quiescent or not.}
\end{figure}
