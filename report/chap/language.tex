% vim:spell:spelllang=en_gb:

In this chapter we will document our prototype language, Join.  The
language is very similar to the original core join-calculus in many
aspects, but has been extended with various syntactic and semantic
features. In the following sections, we will present each extension
and discuss our motivation for including it, as well as the possible
implications that it may have on the difficulty of implementing the
language for real-world applications.

Last we will document the final syntax and semantics of the Join
language.

\section{The Join calculus}
\subsection{Core calculus}

The core calculus is based on the \emph{Reflexive Chemical Abstract Machine}
abbreviated RCHAM, which is a modification of the basic CHAM, defined by Berry
and Boudol in \cite{berry1989chemical}.

The model of computation in the CHAM revolves around the concepts of
\emph{reaction rules} that manipulate \emph{atoms and molecules} in a
\emph{solution}, which is a term comparable to a program. As atoms enter the
solution they recombine until a reaction rule is matched, after which the left
hand side of the matched rule is replaced with the right hand side.

The join calculus builds on this model and defines the concepts of processes
$P$, join patterns $J$ and definitions $D$, which make it up respectively for
the atoms and reaction rules of the CHAM.

The abstract syntax of these constructs are given below.
\begin{displaymath}
\begin{array}{rl}
  P =& \atm x < \tilde v > \\
 |& \defJ D \inJ P
\end{array}\qquad
\begin{array}{rc}
  P =& \atm x < \tilde v > \\
 |& J \andJ J
\end{array}\qquad
\begin{array}{rc}
  D =& D \orJ D \\
 |& J \toJ{} P
\end{array}
\end{displaymath}

A join program consists of an instance of $P$ at the top level. If we denote a
solution by $\D \vdash \A$ where $\D$ are reaction rules and $\A$ is atoms,

\subsection{Pattern matching}
In the core calculus it is only possible to construct join patterns, that match
atom names, fully disregarding the data contents of the atoms. Thus, if one wishes
to have different reactions to take place for different types of content, one
has to use different atom names to signify this.

Consider for example these two similar implementations of a stack, drawn from \cite{MaMa2008AlgPat} :
\begin{displaymath}
\begin{array}{rcll}
\defJ
\\ & &  \atm some<x> \andJ \atm push<y>&\toJ0 \atm some<y:x>
\\ &\orJ&\atm empty<> \andJ \atm push<y> &\toJ0 \atm some<y>
\\ &\orJ&\atm some<x> \andJ \atm pop<k> &\toJ0  \match x \with
\\ &&& \qquad         x':[] \to \atm k<x> \andJ \atm empty<>
\\ &&& \qquad    | x':xs \to \atm k<x> \andJ \atm some<xs>
\\&\inJ& \atm empty<> \andJ \ldots
\\
\\\defJ &&&
\\ & &   \atm stack<x> \andJ \atm push<y> &\toJ0 \atm stack<y:x>
\\&\orJ&  \atm stack<x:xs> \andJ \atm pop<k>& \toJ0 \atm stack<xs> \andJ \atm k<x>
\\&\inJ& \atm stack<[]> \andJ \ldots
\end{array}
\end{displaymath}

Even superficial inspection reveals the latter to be preferable, as it is both
more compact, more readable and more intuitive to someone who has tried
programming with pattern matching like that of ML or Haskell.

Also, it simply seems as a natural extension of the core join calculus.

Because of this we have decided to include pattern matching on join patterns in our system.
The precise semantics of pattern matching can be found in Figure \ref{fig:rule:pat}.

\subsection{Distribution and mobility extension}
The model of distribution is based on the concept of \emph{locations}, which
are named collections of definitions and atoms, thus comprising separate
join-calculus machines. Besides this, locations are characterised by being able
to migrate from site to site by producing a special atom, $\Go<a,k>$, where $a$
is the name of the destination location and $\atm k <>$ is a continuation to be
triggered upon successful migration. Furthermore they are able to become inert
by producing the special atom, $\Halt<>$, in their context.

As a consequence, locations form a hierarchy or tree, that changes throughout
the execution of the join program as locations migrate and halt.
When a location decides to migrate or halt, the decision has consequences for
the entire branch of the location tree, of which the migrating or halting
location is the root. Therefore, when a location migrates, the entire set of
sublocations also migrates, and halting similarly halts every sublocation.

\subsection{Realtime extension}

The core join-calculus has no notion of time, which makes it
impossible to reason about the behaviour of programs with real-time
constraints.  For instance, in distributed systems, it is common to
place a time constraint on external requests, to make sure that a
program don't wait for a response forever if a message should get
lost, or if the program in the other end crashes. To express a
constraint like that in the core join calculus would require that we
rely on a specific implementation being able to generate a message on
a given time interval:
\begin{align*}
  \textbf{def}\quad & \S k<x> ~|~ \S incall<> \triangleright P_{ok} \\
  \land\quad & \S timeout<> ~|~ \S incall<> \triangleright P_{error} \\
  \textbf{in}\quad & \S remotecall<k> ~|~ \S starttimer<timeout, 10>
                                      ~|~ \S incall<>
\end{align*}
In the example above, \emph{remotecall} is given $10$ time units to
return a result on the name \emph{k}. If \emph{k} makes it before the
time limit, the process $P_{ok}$ is started, otherwise the process
$P_{error}$ starts.  There is a problem with this approach though:
Even though we can provide a Join-implementation that does exactly as
described, there is no guarantee that the program will behave in a
similar way on different implementations.

The problem lies both in the non-deterministic choice between the two
reaction rules, and in the fact that messages are not required to be
processed in the same order as they arrive. Even if a result arrives
before the timeout fires, a valid implementation can choose to wait
for the \emph{timeout} message to appear, and consume that instead of
the \emph{k} message.

A possible solution to this problem is to extend the join-calculus
with a notion of time. Many other non-timed process calculi, including
CSP and CCS, has already been extended for this purpose. An overview
of some of the work that has been done in this area along with an
attempt to generalize some of the concepts of timed process calculi
has been presented in \cite{nicollin-overview}.

A timed extension also exists for join-calculus, called Timed Join
Calculus \cite{timed-join}. The calculus is extended with a model of
time using a \emph{discrete time domain}, where every process bears a
time tag denoting when it will be able to participate in a reaction.
The syntax is extended with a new tagging construction for processes,
and all reactions are tagged with a
\emph{delay} tag:
\begin{align*}
  P ::={} & ...    & D ::={}& J \stackrel{d}{\triangleright} P \\
          & t : P  &        & D \land D
\end{align*}
We can now model the example above without depending on special
messages that get captured by the environment:
\begin{align*}
  \textbf{def}\quad & \S k<x> ~|~ \S incall<> \triangleright P_{ok} \\
  \land\quad & \S incall<> \stackrel{16}{\triangleright} P_{error} \\
  \textbf{in}\quad & \S 0:remotecall<k> ~|~ \S 0:incall<>
\end{align*}
Here, we assume that the response message \emph{k} gets transferred
from an external location and gets time tagged as soon as it enters
the local solution.  The second reaction rule is tagged with a delay
of $16$ time units.  This means that every message on the left of
``$\triangleright$'' needs to be available for $16$ time units before
the reaction can happen, effectively allowing another reaction to
``steal'' messages in that time window. Rules with no tags implicitly
gets tagged with a delay of $0$. If the \emph{k} message therefore
arrives before the $16$ time units has passed, the first reaction can
take place immediately.


\subsubsection{Infinite instants}

The time domain in Timed Join Calculus is \emph{abstract}, where time
tags doesn't have any quantifiable correspondence with \emph{physical}
time. It is assumed that any computation takes zero time unless
delayed with a non-zero time tag, which is of course not a realistic
assumption, but as assumption that simplifies the model.
Alternatively, one could assume that any atomic computation took some
minimum amount of time, yielding a model that is closer to reality.
However, as argued in \cite{nicollin-overview}, this destroys the
generality of the model, as we will then tie the behaviour of programs
to an arbitrary assumption about execution speed.

Even if we did make very conservative choices for the minimum duration
of a single computation, this wouldn't make it possible to guarantee
that a given computation finishes in a well-defined time window: Since
a computer has finite computational resources, but can (in theory)
execute an arbitrary number of threads concurrently, the time a
computation takes isn't fixed. As an example, say that we choose that
the duration $\delta$ of a reaction in the CHAM is $1 ms$. For a
single process, this will enable us to guarantee that a computation
involving 20 reactions will finish in $20 ms$. But if we execute an
arbitrary number of instances of this process concurrently on the same
hardware, we can only expect that the time it takes for all the
processes to finish will be proportional to the number of processes.
The actual wall-clock time for a single time step therefore increases,
meaning our hypothetical (though conservative) choice is still too
low. If we increase the number of concurrent processes towards
infinity, even the most conservative choice for $\delta$ will result
in an assumption that we can execute an arbitrary number of reactions
in an instant. The result is a more complicated model with exactly the
same problems as the simpler model, where every computation is assumed
to be instantaneous.

Assuming that every atomic computation takes zero time can pose some
problems in the form of \emph{timelocks} (also called
\emph{Zeno-behaviour}). Since time can only progress when a
computation in an instant is done, a diverging computation can prevent
time from ever progressing, causing a global timelock.  In
\cite{timed-join} this is solved by adding a very restrictive type
system to the join calculus, which rejects all programs that aren't
guaranteed to let time progress. We have chosen not to study this type
system in detail, for several reasons: (1) Identifying all
non-timelocking programs is equivalent to solving the halting problem,
meaning that the set of accepted programs in the proposed type system
is a lot smaller than the actual set of valid programs, making it very
difficult to express useful behaviour. (2) The authors describe the
type system as a ``first attempt'' at solving the problem, and are yet
to prove the soundness of it.


\section{Language definition}

\subsection{Syntax}

The syntax of our prototype language is defined in Figure \ref{fig:syntax}. In
this definition, $x,a$ ranges over names, $s$ range over strings of characters,
and $i,d,t \in \mathbb{N}_0$. All constructions marked with ``*'' are syntactic
sugar, and have equivalent encodings in the core Join language.

\begin{figure}
\begin{align*}
P,Q\quad::={}&             && \textbf{processes} \\
          & 0              && \quad\textrm{inert process} \\
 \alt\quad& x\langle e \rangle
                           && \quad\textrm{asynchronous message} \\
 \alt\quad& P~\&~Q         && \quad\textrm{parallel composition} \\
 \alt\quad& \textbf{def}~D~\textbf{in}~P
                           && \quad\textrm{local definition} \\
 \alt\quad& t : P          && \quad\textrm{timed process} \\
 \alt\quad& \textbf{match}~e~\textbf{with}~\pi_1
               \rightarrow P_1 ~|~ ... ~|~ \pi_n \rightarrow P_n
                           && \quad\textrm{pattern matching} \\
 \alt\quad& \{ I_1; I_2; ...; I_n \}
                           && \quad\textrm{*instruction sequence} \\
D\quad ::={}&              && \textbf{join definitions} \\
         & J \stackrel{d}{\triangleright} P
                           && \quad\textrm{delayed reaction} \\
\alt\quad& D~\textbf{or}~D && \quad\textrm{disjunction} \\
\alt\quad& a[D~\textbf{in}~P] && \quad\textrm{sublocation} \\
j\quad ::={}&             && \textbf{join pattern} \\
            & x\langle y \rangle
                           && \quad\textrm{message} \\
\alt\quad& x(y)
                           && \quad\textrm{*synchronous message} \\
J\quad ::={}&              && \textbf{synchronised join patterns}\\
\alt\quad& j               && \quad\textrm{single message}\\
\alt\quad& j ~\&~ J
                           && \quad\textrm{synchronization} \\
\pi\quad ::={}&            && \textbf{algebraic patterns} \\
         & x               && \quad\textrm{variable} \\
\alt\quad& \kappa(\pi_1, \pi_2, ..., \pi_n)
                           && \quad\textrm{constructor pattern} \\
e\quad ::={}&              && \textbf{expressions} \\
         & i               && \quad\textrm{*integer} \\
\alt\quad& " s "         && \quad\textrm{*string} \\
\alt\quad& x               && \quad\textrm{variable} \\
\alt\quad& \kappa(e_1, e_2, ..., e_n)
                           && \quad\textrm{constructor expression} \\
e^\star\quad ::={}&         && \textbf{*sugared expressions} \\
         & i               && \quad\textrm{*integer} \\
\alt\quad& " s "         && \quad\textrm{*string} \\
\alt\quad& x               && \quad\textrm{*variable} \\
\alt\quad& \kappa(e^\star_1, e^\star_2, ..., e^\star_n)
                           && \quad\textrm{*constructor expression} \\
\alt\quad& x(e^\star_1, e^\star_2, ..., e^\star_ n)
                           && \quad\textrm{*synchronous call} \\
I\quad ::={}&              && \textbf{*instructions} \\
         & \mathbf{let}~\pi~=~e^\star
                           && \quad\textrm{*named values} \\
\alt\quad& \mathbf{run}~P  && \quad\textrm{*asynchronous process} \\
\alt\quad& \mathbf{do}~e^\star && \quad\textrm{*synchronous call} \\
\alt\quad& \textbf{match}~e^\star~\textbf{with}~\pi_1
               \rightarrow \{ I* \} ~|~ ... ~|~ \pi_n \rightarrow \{ I* \}
                           && \quad\textrm{*pattern match} \\
\alt\quad& \textbf{return}~e^\star~\textbf{to}~x
                           && \quad\textrm{*implicit continuation}
\end{align*}
\caption{Syntax of the Join language.\label{fig:syntax}}
\end{figure}


\subsection{Semantics}

We model the state of our system as a series of CHAMs composed in parallel. A
single CHAM is a four tuple $\M = (\D, \A, \phi, t)$ denoted by
\begin{equation*}
 \M ::= \D \mscJ \A
\end{equation*}
where $\D$ is a set of active definitions, $\A$ is a multiset
of present atoms, $\phi$ is an ordered sequence of location names, and $t$ is
a natural number denoting the current time. Multiple CHAMs are composed in
parallel using the operator $\parallel$. We denote one or more CHAMs composed
in parallel by the syntax
\begin{align*}
 \C, \C_1, \C_2 ::={}& \M \\
             |\quad{}& \C_1 \parallel \C_2
\end{align*}

We say that a join pattern $\pi$ \emph{matches} a value $v$, when there exists
a $\sigma$ such that $\sigma \pi = v$, where $\sigma$ is a substitution
function that substitutes closed expressions for variable names.
When checking whether a pattern $\pi$ matches an expression $v$, we denote it
with
\begin{equation*}
  \boxed{\P(\pi,v) \leadsto \hat\sigma}
\end{equation*}
Where $\hat\sigma$ can denote that a pattern either matches or \emph{fails} to
match a process:
\begin{align*}
 \hat\sigma ::={}& \sigma \\
         |\quad{}& fail
\end{align*}

The inference rules for pattern matching are given in Figure \ref{fig:rule:pat}.

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\P(\pi, v) \leadsto \hat\sigma$}
\begin{equation*}
\inferrule[Pat-Var]
{~}
{\P(x,v) \leadsto (x \mapsto v)}
\end{equation*}
\begin{equation*}
\inferrule[Pat-Cons]
{\pi = \kappa(\pi_1, \pi_2, ..., \pi_n)
\\ v = \kappa(v_1, v_2, ..., v_n)
\\ \P(\pi_1,v_1) \leadsto \sigma_1
\\ \P(\pi_2,v_2) \leadsto \sigma_2
\\ ...
\\ \P(\pi_n,v_n) \leadsto \sigma_n}
{
 \P(\pi,v) \leadsto \sigma_1 \cup \sigma_2 \cup ... \cup \sigma_n
}
\end{equation*}
\begin{equation*}
\inferrule[Pat-Cons-Fail]
{\pi = \kappa(\tilde\pi)
\\ v = \kappa'(\tilde v)
\\ \kappa \not= \kappa'
}
{
 \P(\pi, v) \leadsto fail
}
\end{equation*}
\begin{equation*}
\inferrule[Pat-Cons-SubFail]
{\pi = \kappa(\pi_1, \pi_2, ..., \pi_n)
\\ v = \kappa(v_1, v_2, ..., v_m)
\\ \P(\pi_i, v_i) \leadsto fail
}
{
 \P(\pi, v) \leadsto fail
}
\end{equation*}
\end{minipage}}
\caption{Inference rules for pattern matching.} \label{fig:rule:pat}
\end{figure}

\subsubsection{Time}
We include a relaxed version of the time semantics from \cite{timed-join}. Our
version of the semantics provides less guarantees about the order in which
messages are processed, but they still force all computations at a given instant
$t$ to complete before computations involving messages with a delay tag larger
than $t$ can happen. Each CHAM is also explicitly tagged with a natural number
that denotes the current time. This explicit tagging does not occur in
\cite{timed-join}, but is added to these semantics because:
\begin{enumerate}
 \item It enables us to synchronise every machine in the system on a global
 clock. This is necessary to make progress of time deterministic, which makes
 it easier to reason about prototype programs written in Join.
 \item By having the current time available in all reduction rules, we can
 avoid having to generate all possible transitions from a given state and then
 choose the ``earliest''. It is not clear how an actual implementation should
 do this in a feasible manner.
\end{enumerate}

\subsubsection{Unreliable channels}
We make unreliable communication between locations an explicit part of the
semantics. This is done to make the model of unreliable communication
deterministic, making it easier to evaluate how well different revisions of a
program handles lost messages.

We introduce the $\diamond$ and $\times$ relations, which relates pairs of
location names at specific times. For example, when locations $a$ and $b$ can
communicate at time $t$, we denote it by
\begin{equation*}
 \boxed{a \linkUp{t} b}
\end{equation*}
Conversely, if the connection between locations $a$ and $b$ are broken at time
$t$, we denote it by
\begin{equation*}
 \boxed{a \linkDown{t} b}
\end{equation*}

The two relations are disjoint, so whenever we have $a \linkUp{t} b$ we don't
have $a \linkDown{t} b$ and vice-versa.

\subsubsection{Heating}
In the original join-calculus definition, a set of reversible heating/cooling
rules is given. These rules are then implicitly applied to satisfy the
side-conditions of each reduction rule. This results in a system which is very
concisely described, but it doesn't give any direct hints as to when an actual
implementation should apply heating or cooling rules.

Our semantics are a lot more verbose, but provides a directed set of rules
which explicitly specifies when to heat atoms. We have also excluded the
reverse relations, so cooling will never occur.

Heating of a definition construct $D$ into a set of single reaction rules and
sublocation definitions $\D'$ are denoted by the judgement form
\begin{equation*}
  \boxed{\widehat\H(D) \leadsto \D'}
\end{equation*}

Heating of a processes $P$ into a definition set $\D'$ and a set of messages
$\A'$ is denoted by the judgement form
\begin{equation*}
  \boxed{\H(P) \leadsto (\D', \A')}
\end{equation*}
The inference rules for heating is defined in Figure \ref{fig:rule:heat}.

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\mathcal{H}(P) \leadsto (\D', \A')$}
\doms{$\widehat\H(D) \leadsto \D'$}
\begin{equation*}
\inferrule[Heat-Or]
{D = D_1~\mathbf{or}~D_2
\\ \widehat\H(D_1) \leadsto \D_1
\\ \widehat\H(D_2) \leadsto \D_2}
{\widehat\H(D) \leadsto \D_1 \cup \D_2}
\end{equation*}
\begin{equation*}
\inferrule[Heat-Reaction]
{D = J \stackrel{d}{\triangleright} Q}
{\widehat\H(D) \leadsto \{ D \}}
\qquad
\inferrule[Heat-Location]
{D = a[D~\mathbf{in}~P]}
{\widehat\H(D) \leadsto \{ D \}}
\end{equation*}
\begin{equation*}
\inferrule[Heat-Msg]
{P = \atm t:x<v>}
{\H(P) \leadsto (\emptyset, \{P\})}
\qquad
\inferrule[Heat-Inert]
{P = t : 0}
{\H(P) \leadsto (\emptyset, \emptyset)}
\end{equation*}
\begin{equation*}
\inferrule[Heat-Par]
{P = t : (P_1~\&~P_2)
\\ \H(t:P_1) \leadsto (\D_1, \A_1)
\\ \H(t:P_2) \leadsto (\D_2, \A_2)
}
{\H(P) \leadsto (\D_1 \cup \D_2, \A_1 \uplus \A_2)}
\end{equation*}
\begin{equation*}
\inferrule[Heat-Time]
{P = t:(t':P)
\\ \H((t+t'):P) \leadsto (\D, \A)
}
{\H(P) \leadsto (\D,\A)}
\end{equation*}
\begin{equation*}
\inferrule[Heat-Def\footnote{Where $\sigma_{dv}$ replaces fresh names for defined variables.}]
{P = t:\mathbf{def}~D~\mathbf{in}~P
\\ \widehat\H(\sigma_{dv} D) \leadsto \D_1
\\ \H(t: \sigma_{dv} P) \leadsto (\D_2, \A)
}
{\H(P) \leadsto (\D_1 \cup \D_2, \A)}
\end{equation*}
\begin{equation*}
\inferrule[Heat-Match]
{P = t:\mathbf{match}~e~\mathbf{with}~\pi \rightarrow Q~|~\Pi
\\ \P(\pi,e) \leadsto \sigma
}
{\H(P) \leadsto (\emptyset, \{ t : \sigma Q \})}
\end{equation*}
\begin{equation*}
\inferrule[Heat-Match-Next]
{P = t:\mathbf{match}~e~\mathbf{with}~\pi \rightarrow Q~|~\Pi
\\ \P(\pi,e) \leadsto fail
\\ P' = t:\mathbf{match}~e~\mathbf{with}~\Pi
\\ \H(P') \leadsto (\D, \A)
}
{\H(P) \leadsto (\D,\A)}
\end{equation*}
\begin{equation*}
\inferrule[Heat-NoMatch]
{P = t:\mathbf{match}~e~\mathbf{with}~\emptyset}
{\H(P) \leadsto (\emptyset, \{ \atm t:halt<> \}) }
\end{equation*}
\end{minipage}}
\caption{Heating rules}\label{fig:rule:heat}
\end{figure}


\subsubsection{Reactions}

When triggering a reaction in a local machine, we first need to determine if
all the required messages are present in the solution. Checking whether a
single join pattern (that is, a join pattern with no synchronisation) is
satisfied, is denoted by
\begin{equation*}
 \boxed{\widehat\P(J,\A) \leadsto \T_\J}
\end{equation*}
where the syntax of $\T_\J$ can denote either success or failure:
\begin{align*}
 \T_\J ::= {}& (t, \sigma, \A') \\
       |\quad& fail
\end{align*}

This means that if we can conclude $\widehat\P(J, \A) \leadsto (t,\sigma,\A')$,
then the join pattern $J$ can be matched at time $t$ using messages from
solution $\A$, yielding a smaller set of atoms $\A'$ and a substitution
function $\sigma$ which replaces closed expressions for the free variables in
$J$. The inference rules for single join pattern matching is defined in Figure
\ref{fig:rule:join}.

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\widehat\P(J,\A) \leadsto \T_\J$}
\begin{equation*}
\inferrule[Join-FailEmpty]
{~}
{\widehat\P (J, \emptyset) \leadsto fail}
\end{equation*}
\begin{equation*}
 \inferrule[Join-Match]
{
   \A = \{ \atm t:x<v> \} \uplus \A'
\\ \P(\pi, v) \leadsto \sigma
}
{
  \widehat\P(\atm x<\pi>, \A) \leadsto (t, \sigma, \A')
}
\end{equation*}
\begin{equation*}
\inferrule[Join-SubMatch1]
{ \A = \{t : \atm x<v> \} \uplus \A'
\\ \P(\pi, v) \leadsto fail
\\ \widehat\P(\atm x<\pi>, \A') \leadsto (t',\sigma,\A'')
}
{ \widehat\P(\atm x<\pi>, \A) \leadsto (t', \sigma, \{ \atm t:y<v> \} \uplus \A'' ) }
\end{equation*}
\begin{equation*}
\inferrule[Join-SubMatch2]
{ \A = \{t : \atm y<v> \} \uplus \A'
\\ x \not= y
\\ \widehat\P(\atm x<\pi>, \A') \leadsto (t',\sigma,\A'')
}
{ \widehat\P(\atm x<\pi>, \A) \leadsto (t', \sigma, \{ \atm t:y<v> \} \uplus \A'' ) }
\end{equation*}
\begin{equation*}
\inferrule[Join-FailName]
{ \A = \{ \atm t:y<v> \} \uplus \A'
\\ x \not= y
\\ \widehat\P(\atm x<\pi>, \A') \leadsto fail
}
{\widehat\P(\atm x<\pi>, \A) \leadsto fail }
\end{equation*}
\begin{equation*}
\inferrule[Join-FailMatch]
{ \A = \{\atm t:x<v> \} \uplus \A'
\\ \P(\pi, v) \leadsto fail
\\ \widehat\P(\atm x<\pi>, \A') \leadsto fail
}
{\widehat\P(\atm x<\pi>, \A) \leadsto fail }
\end{equation*}
\end{minipage}}
\caption{Rules for matching single join patterns with failure detection.\label{fig:rule:join}}
\end{figure}

A rule $D = J_1~\&~J_2~\&~...~\&~J_n \stackrel{d}{\triangleright}Q$ is
executed when we can successively conclude $\widehat\P(J,\A) \leadsto (t,
\sigma, \A')$ for all join patterns in $D$. When a rule $D$ can execute at time
$t$ in a solution of messages $\A$, we denote it by
\begin{equation*}
\boxed{\R_r(D,\A,t) \leadsto \T_r}
\end{equation*}
where the syntax of $\T_r$ can denote either success or failure:
\begin{align*}
\T_r ::={}& (P,\A')\\
    |\quad& fail
\end{align*}

This means that if we can conclude $\R_r(D,\A,t) \leadsto (P,\A')$, then the
rule $D$ can be executed in the message solution $\A$ at time $t$, yielding a
smaller set of messages $\A'$ and a new process $P$. The inference rules for
detecting reactions in a machine is defined in Figure \ref{fig:rule:def}.

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\R_r(D,\A,t) \leadsto \T_r$}
\begin{equation*}
\inferrule[Def-Match-Bottom]
{
   D = \atm x<\pi> \stackrel{d}{\triangleright} Q
\\ \widehat\P(\atm x<\pi>, \A) \leadsto (t', \sigma, \A')
\\ t'+d \leq t }
{ \R_r(D,~\A,~t) \leadsto (\sigma Q, \A') }
\end{equation*}
\begin{equation*}
\inferrule[Def-Match]
{ D = (\atm x<\pi> ~\&~ J') \stackrel{d}{\triangleright} Q
\\ \widehat\P(\atm x<\pi>, \A) \leadsto(t', \sigma, \A')
\\ t' + d \leq t
\\ \R_r(J' \stackrel{d}{\triangleright} Q, ~\A', ~t) \leadsto (Q', \A'') }
{ \R_r(D,A,t) \leadsto (\sigma Q', \A'') }
\end{equation*}
\begin{equation*}
\inferrule[Def-Fail-Late-Bottom]
{ D = \atm x<\pi> \stackrel{d}{\triangleright} Q
\\ \widehat\P(\atm x<\pi>, \A) \leadsto (t',\sigma,\A')
\\ t'+d>t
}
{\R_r(D,~\A,~t) \leadsto fail}
\end{equation*}
\begin{equation*}
\inferrule[Def-Fail-Late]
{D = (\atm x<\pi> ~\&~ J') \stackrel{d}{\triangleright} Q
\\ D' = J \stackrel{d}{\triangleright} Q
\\ \widehat\P(\atm x<\pi>,\A) \leadsto (t', \sigma, \A')
\\ t'+d>t
}
{
  \R_r(D,\A,t) \leadsto fail
}
\end{equation*}
\begin{equation*}
\inferrule[Def-Fail-Sub]
{D = (\atm x<\tilde\pi> ~\&~ J') \stackrel{d}{\triangleright} Q
\\ D' = J \stackrel{d}{\triangleright} Q
\\ \widehat\P(\atm x<\tilde\pi>,\A) \leadsto (t', \sigma, \A')
\\ \R_r(D',\A',t) \leadsto fail
}
{
  \R_r(D,\A,t) \leadsto fail
}
\end{equation*}
\begin{equation*}
\inferrule[Def-Fail-NoMatch-Bottom]
{ D = \atm x<\tilde\pi> \stackrel{d}{\triangleright} Q
\\ \widehat\P(\atm x<\tilde\pi>, \A) \leadsto fail
}
{\R_r(D,~\A,~t) \leadsto fail}
\end{equation*}
\begin{equation*}
\inferrule[Def-Fail-NoMatch]
{D = (\atm x<\tilde\pi> ~\&~ J') \stackrel{d}{\triangleright} Q
\\ \widehat\P(\atm x<\tilde\pi>, \A) \leadsto fail
}
{
  \R_r(D,\A,t) \leadsto fail
}
\end{equation*}
\end{minipage}}
\caption{Rules for triggering reactions in a solution of messages, and at the same time detecting whether a reaction is able to trigger or not.\label{fig:rule:def}}
\end{figure}

When checking if a machine $M$ can take an internal computational step, we
denote it by
\begin{equation*}
\boxed{\R_m(\M) \leadsto \T_m}
\end{equation*}
where the syntax of $\T_m$ denotes either the next machine state or quiescence:
\begin{align*}
 \T_m ::={}& \M' \\
   |\quad{}& quiescent
\end{align*}

Concluding $\R_m(\M) \leadsto \M'$ means that the machine $M$ can take a step
and become $\M'$, and concluding $\R_m(\M) \leadsto quiescent$ means that the
machine is \emph{stuck}, and can't execute any of its reaction rules at the
current instant. We have not proven it, but we hypothesise that for any
machine, concluding $\R_m(\M) \leadsto x$ and $\R_m(\M) \leadsto y$ implies
$x=y$. The inference rules for machine internal computation is defined in
Figure \ref{fig:rule:machine}. Note that only fully heated processes are added
to the message set, meaning that any message set $\A$ only contains processes
of the form $\atm t:x<v>$. \fixme{Attempting to prove these hypotheses seems
outside the scope of this project?}

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\R_m(\M) \leadsto \T_m$}

\begin{equation*}
\inferrule[Machine-Step]
{\R_m(\M) \leadsto \M' }
{ \M \longrightarrow \M' }
\end{equation*}

\begin{equation*}
\inferrule[Machine-React]
{\M = \D \vdash_t^\phi \A
 \\ \D = \D' \cup \{ J \stackrel{d}{\triangleright} Q \}
 \\ \R_r(J \stackrel{d}{\triangleright} Q, \A, t) \leadsto (Q', \A')
 \\ \H(Q') \leadsto (\D^{new}, \A^{new})
}
{
 \R_m(\M) \leadsto \D \cup \D^{new} \vdash_t^\phi \A' \uplus \A^{new}
}
\end{equation*}

\begin{equation*}
\inferrule[Machine-React-Next]
{\M = \D \vdash_t^\phi \A
 \\ \D = \D' \cup \{ J \stackrel{d}{\triangleright} Q \}
 \\ \R_r(J \stackrel{d}{\triangleright} Q, \A, t) \leadsto fail
 \\ \R_m(\D' \vdash_t^\phi \A) \leadsto \D^{new} \vdash_t^\phi \A^{new}}
{ \R_m(\M) \leadsto \D^{new} \cup \{ J \stackrel{d}{\triangleright} Q \} \vdash_t^\phi \A^{new} }
\end{equation*}

\begin{equation*}
\inferrule[Machine-Quiescent]
{\M = \D \vdash_t^\phi \A
 \\ \D = \D' \cup \{ J \stackrel{d}{\triangleright} Q \}
 \\ \R_r(J \stackrel{d}{\triangleright} Q, \A, t) \leadsto fail
 \\ \R_m(\D' \vdash_t^\phi \A) \leadsto quiescent
}
{ \R_m(\M) \leadsto quiescent }
\end{equation*}
\begin{equation*}
\inferrule[Machine-Quiescent-Bottom]
{~}
{\emptyset \vdash_t^\phi \A \leadsto quiescent}
\end{equation*}
\end{minipage}}
\caption{Rules for doing reactions in a single machine, and at the same time
detecting whether it is quiescent or not.\label{fig:rule:machine}}
\end{figure}


\subsubsection{Distribution}

Any machine $\D \vdash_t^\phi \A$ in the system can spawn new new sublocations,
which will have the form $\D' \vdash_t^{\phi a} \A'$, i.e. they have a unique
name $a$ and their parent location string $\phi$ as a prefix of their own.

Checking if a system $\C$ can spawn sublocations is denoted by
\begin{equation*}
\boxed{\F(\C) \leadsto \T_\F}
\end{equation*}
where the syntax $\T_\F$ can denote either quiescence or the next system state:
\begin{align*}
 \T_\F ::={}& \C' \\
    |\quad{}& quiescent
\end{align*}
The inference rules for sublocation spawning is defined in Figure
\ref{fig:rule:spawn}.

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\F(\C) \leadsto \T_\F$}
\begin{equation*}
\inferrule[Spawn-Rec-Left]
{\C = \C_1~||~\C_2
\\ \F(\C_1) \leadsto \C'}
{\F(\C) \leadsto \C'~||~\C_2}
\qquad
\inferrule[Spawn-Rec-Right]
{\C = \C_1~||~\C_2
\\ \F(\C_2) \leadsto \C'}
{\F(\C) \leadsto \C_1~||~\C'}
\end{equation*}
\begin{equation*}
\inferrule[Spawn-Rec-Quiescent]
{\C = \C_1~||~\C_2
\\ \F(\C_1) \leadsto quiescent
\\ \F(\C_2) \leadsto quiescent}
{\F(\C) \leadsto quiescent}
\end{equation*}
\begin{equation*}
\inferrule[Spawn]
{\C = \D \vdash_t^\phi \A
\\ \D = \D' \cup \{ a[D~\mathbf{in}~P] \}
\\ \widehat\H(D) \leadsto \D_1^{new}
\\ \H(t:P) \leadsto (\D_2^{new}, \A^{new})
}
{ \F(\C) \leadsto \D' \vdash_t^\phi \A ~||~ \D_1^{new} \cup \D_2^{new} \vdash_t^{\phi a} \A^{new} }
\end{equation*}
\begin{equation*}
\inferrule[Spawn-Sub]
{\C = \D \vdash_t^\phi \A
\\ \D=\D' \cup \{ J \stackrel{d}{\triangleright} Q \}
\\ \F(\D' \vdash_t^\phi \A) \leadsto \D'' \vdash_t^\phi \A ~||~ \C'}
{\F(\C) \leadsto \D'' \cup \{J \stackrel{d}{\triangleright} \Q \} \vdash_t^\phi \A ~||~ \C'}
\end{equation*}
\begin{equation*}
\inferrule[Spawn-Sub-Quiescent]
{\C = \D \vdash_t^\phi \A
\\ \D=\D' \cup \{ J \stackrel{d}{\triangleright} Q \}
\\ \F(\D' \vdash_t^\phi \A) \leadsto quiescent}
{ \F(\C) \leadsto quiescent }
\end{equation*}
\begin{equation*}
\inferrule[Spawn-Quiescent]
{\C = \emptyset \vdash_t^\phi \A}
{\F(\C) \leadsto quiescent}
\end{equation*}
\end{minipage}}
\caption{Sublocation spawning rules}\label{fig:rule:spawn}
\end{figure}

If a machine contains a message with a port name defined on another machine in
the system, the message automatically gets transferred to that other machine,
enabling the machines to communicate.

Modelling that communication in our semantics proved to be a little involved,
and requires some auxiliary relations dividing message exchange into
two ``stages''; extraction and insertion.

Message extraction is denoted by
\begin{equation*}
\boxed{\E(\C) \leadsto (\C', \beta)}
\end{equation*}

If we can conclude $\E(\C) \leadsto (\C', \beta)$ for a system $\C$, then we
can extract a set of non-local messages $\beta$ from $\C$, yielding a new
system $\C'$ where the messages are removed from the respective machines. Every
element in $\beta$ has the form $(a, P)$ where $a$ is the unique name of the
machine that the message $P$ was extracted from. Inference rules for message
extraction is defined in Figure \ref{fig:rule:extract}.

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\E(\C) \leadsto (\C', \beta)$}
\begin{equation*}
\inferrule[Extract-Empty]
{\C = \D \vdash_t^\phi \emptyset}
{\E(\C) \leadsto (\C, \emptyset)}
\end{equation*}
\begin{equation*}
\inferrule[Extract-Nonlocal\footnote{With side-condition $x \not\in dv(\D)$}]
{\C = \D \vdash_t^{\phi a} \A' \uplus \{ \atm t:x<v> \}
\\ \E(\D \vdash_t^{\phi a} \A') \leadsto (\C', \beta) }
{\E(\C) \leadsto (\C', \beta \uplus \{ (a, \atm x<v>) \})}
\end{equation*}
\begin{equation*}
\inferrule[Extract-Local\footnote{With side-condition $x \in dv(\D) \lor x = \mathit{go} \lor x = \mathit{halt}$}]
{\C = \D \vdash_t^\phi \A' \uplus \{ \atm t:x<v> \}
\\ \E(\D \vdash_t^\phi \A') \leadsto (\D \vdash_t^\phi \A'', \beta)
}
{\E(\C) \leadsto (\D \vdash_t^\phi \A'' \uplus \{ \atm t:x<v> \}, \beta) }
\end{equation*}
\begin{equation*}
\inferrule[Extract-Rec]
{ \C = \C_1 ~||~ \C_2
\\ \E(\C_1) \leadsto (\C_1', \beta_1)
\\ \E(\C_2) \leadsto (\C_2', \beta_2)
}
{ \E(\C) \leadsto (\C_1' ~||~ \C_2', \beta_1 \uplus \beta_2) }
\end{equation*}
\end{minipage}}
\caption{Rules for extracting non-local messages from machines.}\label{fig:rule:extract}
\end{figure}

Message insertion is denoted by
\begin{equation*}
\boxed{\I(\C, \beta) \leadsto (\C', \beta')}
\end{equation*}

If we can conclude $\I(\C, \beta) \leadsto (\C', \beta')$ for a system $\C$ and
a set of incoming messages $\beta$, we can insert the messages from $\beta$
into the respective receiver machines in $\C$, yielding a new system state
$\C'$ and a set of messages $\beta'$ that had no receivers. Messages are
inserted in the current instant of the machine. The rules for message insertion
are defined in Figure \ref{fig:rule:insert}.

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\I(\C, \beta) \leadsto (\C', \beta')$}
\begin{equation*}
\inferrule[Insert-Local\footnote{With side-condition $x \in dv(\D).$}]
{\C = \D \vdash_t^{\phi b} \A
\\ \beta = \beta' \uplus \{ (a, \atm x<v>) \}
\\ \I(\C, \beta') \leadsto (\D \vdash_t^{\phi b} \A', \beta'')
\\ a \linkUp{t} b}
{\I(\C, \beta) \leadsto (\D \vdash_t^{\phi b} \A' \uplus \{ \atm (t+1):x<v> \}, \beta'') }
\end{equation*}

\begin{equation*}
\inferrule[Insert-Lost\footnote{With side-condition $x \in dv(\D).$}]
{\C = \D \vdash_t^{\phi b} \A
\\ \beta = \beta' \uplus \{ (a, \atm x<v>) \}
\\ \I(\C, \beta') \leadsto (\D \vdash_t^{\phi b} \A', \beta'')
\\ a \linkDown{t} b}
{\I(\C, \beta) \leadsto (\D \vdash_t^{\phi b} \A', \beta'') }
\end{equation*}

\begin{equation*}
\inferrule[Insert-Nonlocal\footnote{With side-condition $x \not\in dv(\D).$}]
{\C = \D \vdash_t^{\phi b} \A
\\ \beta = \beta' \uplus \{ (a, \atm x<v>) \}
\\ \I(\C, \beta') \leadsto (\D \vdash_t^{\phi b} \A', \beta'')
}
{\I(\C, \beta) \leadsto (\D \vdash_t^{\phi b} \A', \beta'' \uplus (a, \{ \atm x<v> )\}) }
\end{equation*}

\begin{equation*}
\inferrule[Insert-Empty]
{~}
{\I(\C, \beta) \leadsto (\C, \emptyset)}
\end{equation*}
\end{minipage}}
\caption{Rules for inserting external messages into machines.}\label{fig:rule:insert}
\end{figure}

The combined action of sequentially extracting and inserting messages in a
system is denoted by
\begin{equation*}
\boxed{\X(\C) \leadsto \T_\X}
\end{equation*}
where the syntax $\T_\X$ either denotes successful message exchange or
quiescence (i.e. no machine has non-local messages):
\begin{align*}
 \T_\X ::={}& \C' \\
    |\quad{}& quiescent
\end{align*}

The inference rules for message exchange is defined in Figure \ref{fig:rule:exchange}.

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\X(\C) \leadsto \T_\X$}
\begin{equation*}
\inferrule[Exchange-Quiescent]
{\E(\C) \leadsto (\C', \emptyset)}
{\X(\C) \leadsto quiescent}
\end{equation*}
\begin{equation*}
\inferrule[Exchange\footnote{With side-condition $\beta \not= \emptyset$.}]
{\E(\C) \leadsto (\C', \beta)
\\\I(\C', \beta) \leadsto (\C'', \beta') }
{ \X(\C) \leadsto \C'' }
\end{equation*}
\end{minipage}}
\caption{Rules for exchanging messages between machines and detecting when all
messages have been delivered.}\label{fig:rule:exchange}
\end{figure}


\subsubsection{Mobility and failure}

In order to define the rules for mobility and failure, we need an auxiliary
definition of mappings between unique machine identifiers and their fully
qualified location sequence. Such a map is denoted by the syntax
\begin{align*}
\Sigma ::={}& (a \mapsto \phi) \\
    |\quad{}& \Sigma_1 \cup \Sigma_2
\end{align*}

Looking up the path for the name $a$ in a map $\Sigma$ is denoted by
\begin{equation*}
\boxed{\U(\Sigma, a) \leadsto \T_\Sigma}
\end{equation*}
where the syntax of $\T_\Sigma$ can denote either success or failure ($\bot$):
\begin{align*}
 \T_\Sigma ::={}& \phi \\
        |\quad{}& \bot
\end{align*}

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\U(\Sigma, a) \leadsto \T_\Sigma$}
\doms{$\T_\Sigma ::= \bot ~|~ \phi$}

\begin{equation*}
\inferrule[Map-Match]
{\Sigma = (a \mapsto \phi)}
{\U(\Sigma, a) \leadsto \phi}
\qquad
\inferrule[Map-Nomatch\footnote{With side-condition $a \not= b$.}]
{\Sigma = (b \mapsto \phi)}
{\U(\Sigma, a) \leadsto \bot}
\end{equation*}

\begin{equation*}
\inferrule[Map-Match-Left]
{\Sigma = \Sigma_1 \cup \Sigma_2
\\ \U(\Sigma_1, a) \leadsto \phi}
{\U(\Sigma, a) \leadsto \phi}
\end{equation*}

\begin{equation*}
\inferrule[Map-Match-Right]
{\Sigma = \Sigma_1 \cup \Sigma_2
\\ \U(\Sigma_1, a) \leadsto \bot
\\ \U(\Sigma_2, a) \leadsto \phi}
{\U(\Sigma, a) \leadsto \phi}
\end{equation*}

\begin{equation*}
\inferrule[Map-Nomatch-Both]
{\Sigma = \Sigma_1 \cup \Sigma_2
\\ \U(\Sigma_1, a) \leadsto \bot
\\ \U(\Sigma_2, a) \leadsto \bot}
{\U(\Sigma, a) \leadsto \bot}
\end{equation*}

\end{minipage}}
\caption{Rules defining the semantics of a key/value map with detection of
non-existing keys.}\label{fig:rule:sigma}
\end{figure}

In order to perform migration of a single machine in the system, we need to
know the fully qualified path of every other machine. The $\Sigma$-map of the
fully qualified paths in the system $\C$ is related to the system by
\begin{equation*}
\boxed{\L(\C) \leadsto \Sigma}
\end{equation*}

The inference rules for location path extraction is defined in Figure
\ref{fig:rule:makemap}.

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\L(\C) \leadsto \Sigma$}
\begin{equation*}
\inferrule[Loc-Insert]
{\C = \D \vdash_t^{\phi a} \A}
{\L(\C) \leadsto (a \mapsto \phi a) }
\end{equation*}
\begin{equation*}
\inferrule[Loc-Par]
{\C = \C_1 ~||~ \C_2
\\ \L(\C_1) \leadsto \Sigma_1
\\ \L(\C_2) \leadsto \Sigma_2}
{\L(\C) \leadsto \Sigma_1 \cup \Sigma_2}
\end{equation*}
\end{minipage}}
\caption{Rules for determining the full prefix of all location names in a
system.}\label{fig:rule:makemap}
\end{figure}



\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\K(\phi, \C) \leadsto \T_\K$}
\doms{$\T_\K ::= \C' ~|~ halt $}
\begin{equation*}
\inferrule[Halt]
{\C = \D \vdash_t^{\phi \beta} \A}
{\K(\phi, \C) \leadsto halt}
\qquad
\inferrule[Halt-NoMatch\footnote{$\phi$ is not a prefix of $\psi$.}]
{
 \C = \D \vdash_t^\psi \A
}
{ \K(\phi, \C) \leadsto \C }
\end{equation*}

\begin{equation*}
\inferrule[Halt-Left]
{\C = \C_1 ~||~ \C_2
\\ \K(\phi, \C_1) \leadsto halt
\\ \K(\phi, \C_2) \leadsto \C_2'}
{  \K(\phi, \C) \leadsto \C_2'}
\end{equation*}

\begin{equation*}
\inferrule[Halt-Right]
{\C = \C_1 ~||~ \C_2
\\ \K(\phi, \C_1) \leadsto \C_1'
\\ \K(\phi, \C_2) \leadsto halt}
{  \K(\phi, \C) \leadsto \C_1'}
\end{equation*}

\begin{equation*}
\inferrule[Halt-Both]
{\C = \C_1 ~||~ \C_2
\\ \K(\phi, \C_1) \leadsto halt
\\ \K(\phi, \C_2) \leadsto halt}
{  \K(\phi, \C) \leadsto halt}
\end{equation*}

\begin{equation*}
\inferrule[Halt-None]
{\C = \C_1 ~||~ \C_2
\\ \K(\phi, \C_1) \leadsto \C_1'
\\ \K(\phi, \C_2) \leadsto \C_2'}
{  \K(\phi, \C) \leadsto \C_1' ~||~ \C_2'}
\end{equation*}

\end{minipage}}
\caption{Rules for halting machines with a specific location prefix.}\label{fig:rule:halt}
\end{figure}


\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\G(\Sigma, \C) \leadsto \T_\G$}
\doms{$\T_\G ::= quiescent ~|~ halt_\phi ~|~ (\C', \phi \mapsto \psi)$}

\begin{equation*}
\inferrule[Detect-Empty-Quiescent]
{\C = \D \vdash_t^\phi \emptyset
}
{\G(\Sigma, \C) \leadsto quiescent}
\end{equation*}

\begin{equation*}
\inferrule[Detect-Late-Quiescent]
{\C = \D \vdash_t^\phi \A' \uplus \{ \atm t':x<v> \}
\\ t' \not= t
\\ \G(\Sigma, \D \vdash_t^\phi \A') \leadsto quiescent
}
{\G(\Sigma, \C) \leadsto quiescent}
\end{equation*}

\begin{equation*}
\inferrule[Detect-Nomatch-Quiescent]
{\C = \D \vdash_t^\phi \A' \uplus \{ \atm t':x<v> \}
\\ x \not= \textit{go}
\\ x \not= \textit{halt}
\\ \G(\Sigma, \D \vdash_t^\phi \A') \leadsto quiescent
}
{\G(\Sigma, \C) \leadsto quiescent}
\end{equation*}

\begin{equation*}
\inferrule[Detect-Halt]
{\C = \D \vdash_t^\phi \A' \uplus \{ \atm t:\mathit{halt}<\unit> \}
}
{\G(\Sigma, \C) \leadsto halt_\phi}
\end{equation*}

\begin{equation*}
\inferrule[Detect-Sub-Halt]
{\C = \D \vdash_t^\phi \A' \uplus \{ \atm t':x<v> \}
\\ \G(\Sigma, \D \vdash_t^\phi \A') \leadsto halt_\phi
}
{\G(\Sigma, \C) \leadsto halt_\phi}
\end{equation*}

\begin{equation*}
\inferrule[Detect-Go-Halt]
{\C = \D \vdash_t^\phi \A' \uplus \{ \atm t:\mathit{go}<\kappa(a,c)> \}
\\ \U(\Sigma, a) \leadsto \bot
}
{\G(\Sigma, \C) \leadsto halt_\phi}
\end{equation*}

\begin{equation*}
\inferrule[Detect-Migrate]
{\C = \D \vdash_t^\phi \A' \uplus \{ \atm t:\mathit{go}<\kappa(a,c)> \}
\\ \U(\Sigma, a) \leadsto \psi
\\ \C' = \D \vdash_t^{\phi b} \A' \uplus \{ \atm t:c<\unit> \}
}
{\G(\Sigma, \C) \leadsto (\C', \phi b \mapsto \psi b)}
\end{equation*}

\begin{equation*}
\inferrule[Detect-Sub-Migrate]
{\C = \D \vdash_t^\phi \A' \uplus \{ P \}
\\ \G(\Sigma, \D \vdash_t^\phi \A') \leadsto (\D \vdash_t^\phi \A'', \phi \mapsto \psi)
\\ \C' = \D \vdash_t^\phi \A'' \uplus \{ P \}
}
{\G(\Sigma, \C) \leadsto (\C', \phi \mapsto \psi)}
\end{equation*}

\end{minipage}}
\caption{Rules for detecting \emph{go} and \emph{halt} atoms.}\label{fig:rule:go-halt}
\end{figure}

\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\doms{$\V(\C, \phi \mapsto \psi) \leadsto \C'$}
\begin{equation*}
\inferrule[Mig-Dont\footnote{With side-condition that $\phi$ is not a prefix of $\phi'$.}]
{\C = \D \vdash_t^{\phi'}}
{\V(\C, \phi \mapsto \psi) \leadsto \C}
\qquad
\inferrule[Mig-Rewrite]
{\C = \D \vdash_t^{\phi\beta}
\\ \C' = \D \vdash_t^{\psi\beta}}
{\V(\C, \phi \mapsto \psi) \leadsto \C'}
\end{equation*}
\begin{equation*}
\inferrule[Mig-Par]
{\C = \C_1 ~||~ \C_2
\\ \V(\C_1, \phi \mapsto \psi) \leadsto \C_1'
\\ \V(\C_2, \phi \mapsto \psi) \leadsto \C_2'}
{\V(\C, \phi \mapsto \psi) \leadsto \C_1' ~||~ \C_2'}
\end{equation*}
\end{minipage}}
\caption{Rules for migrating machines with the same location prefix.}\label{fig:rule:mig}
\end{figure}



\begin{figure}[!h]
\fbox{\begin{minipage}{0.97\textwidth}
\begin{equation*}
\inferrule[Progress]
{\C = \D \vdash_t^\phi \A
\\ \C' = \D \vdash_{t+1}^\phi \A}
{\N(\C) \leadsto \C'}
\end{equation*}

\begin{equation*}
\inferrule[Progress-Sync]
{\C = \C_1 ~||~ \C_2
\\ \N(\C_1) \leadsto \C_1'
\\ \N(\C_2) \leadsto \C_2'}
{\N(\C) \leadsto \C_1' ~||~ \C_2'}
\end{equation*}
\end{minipage}}
\caption{Rules for the progression of time.}\label{fig:rule:progress}
\end{figure}

