
\begin{comment}
Disposition:
------------
*Present usecase, its purpose, inspiration.
*Introduce scenario.
  - Assumptions of underlying system.
  - number of msc etc.
*Show overview pseudo-code and describe implementation.
*Discuss generalisability of the program.
  - Argue that more general server-sensor queries may be constructed,
  - And that more general ad-hoc registration is possible.
\end{comment}

In this chapter we present our implementation of a simplified version of a
distributed query system applied to a sensor net. Essentially it is just an
instance of the \fixme{insert citation!.. think its in join-tutorial.}{applet
server} pattern, although a bit more involved.

The example is heavily inspired by \cite{bonnet2001towards}, and
evolves around a factory warehouse setting where each item has a
stick-on sensor that measures the temperature. There are also
sensors on the walls and ceilings. All sensors have a unique id available to them.

Apart from sensors collecting nodes exist, also called \emph{servers}, that
distribute the queries to the sensors. The term \emph{client} refers to the machine
that distributes queries to the collecting nodes and receives the output of the queries.

\subsection*{Distributed queries in sensor networks}

In \cite{bonnet2001towards}, the concept of sensor databases is
introduced, in which a set of sensors is queried using an extension of
SQL, enabling the user to extract very specific datasets from the
network. The queries are executed in a distributed fashion, so the
sensors only transmit data relevant to the query.  For high-resolution
sensors generating vast amounts of data, processing the data locally
is cheaper than transmitting it for offline processing, leading to a
more efficient usage of resources for bandwidth and battery
constrained devices.

The COUGAR project\cite{COUGAR} has already done a lot of research in this
area, and a complete system for executing declarative queries in a distributed
fashion has already been created. However, it would be interesting to see if a
join-calculus based language would prove useful for expressing programs that
essentially do the same as a distributed query. \cite{bonnet2001towards}
mentions that one of the challenges of implementing distributed queries was
handling the asynchronicity of events, which we hope will be easier to deal
with in a join-calculus based language.

\subsection*{Example scenario}

Due to the lack of data structure libraries and the general ineffeciency of the
interpreter, we only consider a scenario with one collecting node and two
sensors, statically positioned. No new sensors will arrive, but sensor hardware
failure is simulated.

Since our example only features a single collecting node, the server and client
are merged into one machine for simplicity.

The query program that is uploaded to the sensors simply measures the local
temperature and reports the average every $n$'th time instant.  However, if the
sensor registers a temperature above a given threshold it will report it
immediately.

Every $m$'th time instant the server outputs the received temperature readings
along with an assessment of the age of each reading. If a reading isn't updated
within a given time interval, the program assumes that the sensor is broken and
prompts the operator to replace it.

\subsubsection*{Assumptions about the underlying system}

We will assume a network topology with a central processing node
which is connected to the sensors in a star pattern, using
unreliable communication channels (i.e. some sort of radio protocol).
We do not assume that the runtime system ensures delivery of messages,
but we do assume that any messages that \emph{do} get delivered are
ensured not to be corrupted in any way.

However, since we don't have a mature, compiled language, we will not focus on
memory and processor constraints, since the resource usage depends a lot on the
implementation. We may assume, however, that the actual usage of memory
resources is in some way proportional to the number of active messages and join
patterns on each device , and that the usage of computational resources is
proportional to the number of reduction steps required to arrive at a result.

It is also assumed that there is a built in name-exchange facility,
such that the network can be bootstrapped. In our scenario, this is a
global key-value store that can be accessed programmatically from any
device through the API messages \verb!register! and \verb!search!. A
call to one of these messages always succeeds. In a real-world
scenario, bootstrapping an ad-hoc network may be more involved, since
we cannot rely on a global, centralized non-failing database. Most likely one
could be moderatly succesfull by implementing this name-exchange api by
performing regular broadcasts at the \fxnote*{is it called this?}{link-level}
of the network to anyone willing to listen.

The only type of communication that is assumed to be reliable is location
migration, as there is no sensible way to reproduce a location, if it is lost
in transit.

\subsection*{Implementation}

Conceptually, a query program is structured in two parts: One that
treats the sensor data inside the sensor itself, and a second part
that runs on the server node and collects and optionally filters the data from
the sensors and eventually aggregate these to the client.

Sensor:
\begin{verbatim}
def
 ..library definitions..

 or mkSensor<mscId, handshake> |>
    def
        query[
            killQuery<> |> halt<>
         or readTempLoc() |> {return readTemp(mscId) to readTempLoc}
         in 0
        ]
     in handshake<mscId, readTempLoc, query>
 or connect<> |>
      { match search("server") with
          Nothing -> { run 1:connect<> }
        | Just handshake -> { let mscId = machineId()
                           ; run mkSensor<mscId, handshake> } }
 in connect<>
\end{verbatim}

\fixme{prepare for presentation..}

Server:
\begin{verbatim}
def
  [library definitions]
 or mkQuery(threshold, readTemp, callback) |>
                 { let num = 10
                 ; run def query[
                     collect<n, tAkk> |>
                       { let t = readTemp()
                       ; [if threshold <= t then
                           { run callback<Above(t)> & 1:collect<1,t>}
                          else if n=num then
                           { let avg= (t+tAkk)/(1+num)
                           ; run callback<Avg(avg)> & 1:collect<1,avg> }
                          else
                           { let tAkk' = t + tAkk
                                 nextT = n+1
                           ; run 1:collect<nextT, tAkk'>
                           }]
                       }
                  or migrate<locNm> |> { do go(locNm); let t = readTemp(); run collect<1,t>}
                  in 0 ] in {return migrate to mkQuery}
                 }

 or mkServer<> |>
  {
  ; let cl = mkClock(0)
  ; run def
            sensorHandshake<mscId, readT, qLoc> |> {
              match mscId with
                "Sensor_A" -> {let query = mkQuery(20, readT, sensorACallback)
                              ; run query<qLoc>}
              | "Sensor_B" -> {let query = mkQuery(22, readT, sensorBCallback)
                              ; run query<qLoc>}
            }
         or sensorACallback<temp> & collected<Sensors(aT, aN, bT, bN)> |>
                                   { let time = cl()
                                   ; run collected<Sensors(temp, time, bT, bN)>
                                   }
         or sensorBCallback<temp> & collected<Sensors(aT, aN, bT, bN)> |>
                                   { let time = cl()
                                   ; run collected<Sensors(aT, aN, temp, time)>
                                   }
         or printCollected<>
          & collected<data> |> { [output data pretty printed]} & 5:printCollected<>
                                                    & collected<data>
         in collected<Sensors(Above 0,0,Above 0,0)>
          & { do register("server", sensorHandshake) }
          & 5:printCollected<>
  }
 in mkServer<>
\end{verbatim}
\subsection*{Discussion}

\subsubsection*{Doing I/O}

\fixme*{refer to some introduction of the way we handle external input, then delete subsection}{%
We will begin by defining how the sensors will read data from the
outside world. Since the join-calculus has no way of doing I/O, we
have to define some ``magic'' messages that forms an API for reading
temperature values.
}
We read the temperature via explicit probing using the name \verb+read_temperature+.

\subsubsection*{A programmable sensor}

\fxnote{Preserved because it has insights.}
Note that in this use case, we exploit the ability to halt
locations to ensure that any processes that may have migrated to
the sensor is killed when we loose connection to the server. We
also "wrap" our exported API calls in messages defined in the
\verb!here! location. This ensures that the exposed interface is
invalidated whenever the location is killed, ensuring that no
process can continue reading from the sensor from an external
location (which would destroy the purpose of migrating queries to
the sensors in the first place).

\subsubsection*{Programming the central nodes}

\emph{stuff for generalising}
Initially, query programs enter the server node from a client node
through a set of names, that the server node exports.
Then, as sensors register themselves with the server node, the query
programs are uploaded from the server to the sensors.

In order for this to work, a correct query program is supposed to
behave in a certain way with regards to distribution and internal
structure, because process migration in the join calculus only happens on
the initiative of the process that is to migrate, and cannot be controlled
or observed by the surrounding environment.
----
When a new sensor appears in the network, it enters the registration
phase, where the sensor exports the names used for accessing the
sensor hardware, and the filter-part of the query program migrates to
the sensor.
While the sensor is active and registered, any exchange of sensor data
happens only on the initiative of the filter part of the query
program.

Since the nature of queries vary it is up to the query program to determine
what to do if the connection to the server is lost.

